## Small Model
Small Model is very important in many scenarios, such as mobile phones and autopilots. In this section, we compare some various methods about training a small model to generate a baseline of Chinese NLP tasks. And we hope to get a well standard for measuring the ability of small models. 

| Model/Compression Method   | Score  | 参数 | TNEWS  | LCQMC  | XNLI   | INEWS  | BQ     | MSRANER | THUCNEWS | iFLYTEKData |
| :----:| :----: | :----: | :----: |:----: |:----: |:----: |:----: |:----: |:----: |:----: |
| BAM for <a href="https://github.com/google-research/bert">BERT-base</a>        | -- | -- | -- | -- | -- | -- | -- | -- | -- | --  |
| TinyBERT for <a href="https://github.com/google-research/bert">BERT-base</a>        | -- | -- | -- | -- | -- | -- | -- | -- | -- | --  |
### Small Model Trained Directly

### Model Compression

#### Knowledge Distillation

#### Quantization

#### Pruning
